---
title: "Stat-613:Final Project, Predicting Stroke"
author: "Dustin Pierce, Casey Aguilar-Gervase, Abdul Tarawally"
date: "December 2, 2019"
output:
  pdf_document:
    df_print: kable
    dev: png
---

```{r setup, include=FALSE, fig.cap="A caption", out.width = '100%'}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, error = FALSE)
```
  
# Project Set Up

## Package Imports
  
```{r packages, include=FALSE, fig.cap="A caption", out.width = '100%'}
library(tidyverse)
install.packages("caret")
library(caret)
install.packages("png")
library(png)
install.packages("fastDummies")
library(fastDummies)
install.packages("randomForest")
library(randomForest)
install.packages("neuralnet")
library(neuralnet)
install.packages("ROSE")
library(ROSE)
install.packages("e1071")
library(e1071)
install.packages("RColorBrewer")
library(RColorBrewer)
library(devtools)
install_github("vqv/ggbiplot")
library(ggbiplot)
install.packages("tree")
library(tree)
```

## Data Import

Data is manually uploaded to local machine after downloading from [Healthcare Dataset Stroke Data](https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data). Note that the data dictionary loads as a screen shot (png) if directly downloaded from Kaggle. Thus, we rename to `stroke_dataset_dict.png`. We ignore `test_2v.csv` because stroke outcomes are not available. Therefore, we only utilize `train_2v.csv` for project data; in other words, we parse `train_2v.csv` into training and testing data. 

```{r data, eval = TRUE, fig.cap="A caption", out.width = '100%'}
# Manually uploaded data after downloading to local from Kaggle
df <- read_csv("train_2v.csv")
# using png package to display data dictionary 
img <- png::readPNG("/home/rstudio/dx/stroke_dataset_dict.png")
grid::grid.raster(img)
```

# Explortatory Data Analysis 

## Understanding the data

```{r understand_data, eval = TRUE, fig.cap="A caption", out.width = '100%'}
prop.table(table(df$stroke, useNA = "ifany"))*100 # ~ 2% YES stroke (need to balance classes)

summary(df) # will also need indicator/dummy variables for multi-class categorical

unique(df$smoking_status) # NA is viewed as a character but is actually null
unique(df$work_type) # similar NA issue; will need dummary variables for each category
unique(df$Residence_type) # similar NA issue; will need dummary variables for each category
unique(df$gender) # includes "other" option so cannot use binary indicator
unique(df$ever_married) # binary (YES/NO) -- convert to indicator feature
unique(df$hypertension) # binary and numeric!

class(df$id) # numeric -- need to convert to character

## Plotting occurrences of stroke / non-stroke cases (imbalanced classes)
ggplot(data = df, aes(x = stroke)) + 
  geom_bar() + 
  theme_bw() +
  ggtitle("Non-stroke cases (left), Stroke cases (right)") +
  theme(plot.title = element_text(hjust = 0.5))
```
## Exploratory Data Visualization

We experimented with a number of exploratory visualizations and only include ones of interest.

```{r data_viz, eval = TRUE, fig.cap="A caption", out.width = '100%'}
## Continuous variables summarized by work type
# ggplot(data = df, aes(reorder(work_type, bmi), bmi, color = work_type)) +
#   geom_boxplot() +
#   labs(title = "Distribution of BMI by Work Type",x = "work_type") +
#   theme(plot.title = element_text(hjust = .5))

ggplot(data = df, aes(reorder(work_type, age), age, color = work_type)) +
  geom_boxplot() +
  labs(title = "Distribution of Age by Work Type",x = "work_type") +
  theme(plot.title = element_text(hjust = .5))

# ggplot(data = df, aes(reorder(work_type, avg_glucose_level), avg_glucose_level, color = work_type)) +
#   geom_boxplot() +
#   labs(title = "Distribution of Glucose by Work Type",x = "work_type") +
#   theme(plot.title = element_text(hjust = .5))

## Continuous variables summarized by marital status
# ggplot(data = df, aes(reorder(ever_married, age), age, color = ever_married)) +
#   geom_boxplot() +
#   labs(title = "Distribution of Age by Marital Status",x = "work_type") +
#   theme(plot.title = element_text(hjust = .5))

# ggplot(data = df, aes(reorder(ever_married, bmi), bmi, color = ever_married)) +
#   geom_boxplot() +
#   labs(title = "Distribution of BMI by Marital Status",x = "work_type") +
#   theme(plot.title = element_text(hjust = .5))

# ggplot(data = df, aes(reorder(ever_married, avg_glucose_level), avg_glucose_level, color = ever_married)) +
#   geom_boxplot() +
#   labs(title = "Distribution of Glucose by Marital Status",x = "work_type") +
#   theme(plot.title = element_text(hjust = .5))

# ggplot(data = df, aes(reorder(Residence_type, bmi), bmi, color = Residence_type)) +
#   geom_boxplot() +
#   labs(title = "Distribution of BMI by Residence type",x = "Residence_type") +
#   theme(plot.title = element_text(hjust = .5))

ggplot(data = df, aes(reorder(stroke, age), age, color = stroke)) +
  geom_boxplot() +
  labs(title = "Distribution of Age by Stroke outcome",x = "stroke") +
  theme(plot.title = element_text(hjust = .5))

ggplot(data = df, aes(reorder(stroke, avg_glucose_level), avg_glucose_level, color = stroke)) +
  geom_boxplot() +
  labs(title = "Distribution of Glucose by Stroke outcome",x = "stroke") +
  theme(plot.title = element_text(hjust = .5))
```

## Feature Engineering

```{r feature_engineering, eval = TRUE, fig.cap="A caption", out.width = '100%'}
# Engineering features based on above suggestions
df <- df %>% mutate(id = as.character(id),
                    ever_married = ifelse(ever_married == "Yes", 1, 0),
                    gender = ifelse(gender == "Male", 1,
                                    ifelse(gender == "Female", 0, NA)),
                    Residence_type = ifelse(Residence_type == "Urban", 1,
                                            ifelse(Residence_type == "Rural", 0, NA)),
                    # interim fix below, need to add dummy variables for below
                    work_type = as.factor(work_type),
                    smoking_status = as.factor(smoking_status))
# Dropping smoking status for now b/c 31% null -- can revisit on next iteration
(sum(is.na(df$smoking_status))/dim(df)[1])*100
df <- df %>% select(-smoking_status)
## Now will create indicator variables for all categorical features
dummies <- fastDummies::dummy_cols(df %>% select(-id))
dummies <- dummies %>% dplyr::select(-work_type, -work_type_NA) %>% 
  dplyr::rename(work_type_Self_employed = `work_type_Self-employed`)

# Checking overlap
dplyr::setdiff(names(dummies), names(df))
dplyr::setdiff(names(df), names(dummies))

# re-assigning id
dummies$id <- df$id
# Checking equality for common features before and after transform
all.equal(df %>% select(-work_type), dummies %>% select(-work_type_children,
                                                        -work_type_Private,
                                                        -work_type_Self_employed,
                                                        -work_type_Govt_job,
                                                        -work_type_Never_worked))
training_data <- dummies %>% tidyr::drop_na()
(dim(training_data)[1]/dim(df)[1])*100 # preserve ~97% of records after dropping null

summary(training_data)
# Filtering unrealistic values of BMI
max(training_data$bmi, na.rm = TRUE) # doesn't seem realistic according to cdc
training_data <- training_data %>% filter(bmi < 50)
dim(training_data)[1]/dim(dummies)[1] # still have ~95% of original records 

rm(dummies, df)
```

## Comparing Stroke and Non-stroke cases

```{r stroke_cases,echo=TRUE, fig.cap="A caption", out.width = '100%'}
# Comparing stroke versus non-stroke patients
stroke_cases <- training_data %>% filter(stroke == 1)
stroke_cases_no <- training_data %>% filter(stroke == 0)
## stroke victims older compared to non-stroke
# age
summary(stroke_cases$age) # Mean = 68.68, Median = 72 (yrs old)
summary(stroke_cases_no$age) # Mean = 41.41, Median = 43 (yrs old)
# hypertension
summary(stroke_cases$hypertension) # 27% have hypertension compared to 8% for non-stroke
summary(stroke_cases_no$hypertension)
# heart disease
summary(stroke_cases$heart_disease) # 22% have heart disease compared to 4% for non-stroke
summary(stroke_cases_no$heart_disease)
# marriage 
summary(stroke_cases$ever_married) # 89% YES ever married compared to 63% for non-stroke
summary(stroke_cases_no$ever_married)
# glucose levels
summary(stroke_cases$avg_glucose_level) # glucose levels mean/median = 130.25/104.6
summary(stroke_cases_no$avg_glucose_level) # glucose level mean/median = 102.97/91.14
rm(stroke_cases, stroke_cases_no)
```

## Class imbalance

In this section we address the class imbalance problem. Note that in the exploratory sections of the raw data we saw that less than *2%* of observations were stroke cases. Thus, training a model with this imbalance leads to models that always predict **non-stroke** outcomes for all test observations. This is, of course, undesirable. We address this problem by generating synthetic data via random over and under sampling with the *ROSE* package.

From the ROSE package documentation, "*ROSE (Random Over-Sampling Examples) aids the task of binary classification in the presence of rare classes. It produces a synthetic, possibly balanced, sample of data simulated according to a smoothed-bootstrap approach. ... Essentially, ROSE selects an observation belonging to the class k and generates new examples in its neighbourhood, where the width of the neighbourhood is determined by [diagonal covariance matrix]*". Note that class k refers to the response classes and in our case means (`1 = YES stroke`, `0 = NO stroke`). For our use case, we decided to balance the classes in a ratio of 1:1 (`p = 0.5`) and apply conservative shrink factors to each class (`hmult.majo = 0 = hmult.mino`). 

```{r class_balance, eval = TRUE, fig.cap="A caption", out.width = '100%'}
# Original proportions of classes (0 = NO, 1 = YES)
prop.table(table(training_data$stroke))*100
# Setting formula with linear features
formula_linear <- as.formula(stroke ~ gender + age + hypertension + heart_disease + ever_married + Residence_type + avg_glucose_level + bmi + work_type_children + work_type_Private + work_type_Never_worked + work_type_Self_employed + work_type_Govt_job)
########################################################################
## Balancing classed with ROSE package
# 50/50 split
data_rose_0.5 <- ROSE::ROSE(formula_linear, p = 0.5, data = training_data,
                            seed = 123, hmult.majo=0, hmult.mino=0)$data
dim(data_rose_0.5) # 40163 x 14
prop.table(table(data_rose_0.5$stroke))*100 

## ## Plotting occurrences of stroke / non-stroke cases (balanced classes)
ggplot(data = data_rose_0.5, aes(x = stroke)) + 
  geom_bar() + 
  theme_bw() +
  ggtitle("Non-stroke cases (left), Stroke cases (right)") +
  theme(plot.title = element_text(hjust = 0.5))
```

### Principal Component Analysis

In this section we compare explained variance via princple component analysis for class imbalanced and class balanced data. 

```{r pca, eval = TRUE, fig.cap="A caption", out.width = '100%'}
#Principal Component Analysis -- imbalanced classes
pc_imbalanced <- prcomp(training_data %>% select(-id), center = TRUE, scale. = TRUE)
pc_imbalanced$scale # checking the scale to see that the sd is calculated for each variable.
print(pc_imbalanced)
summary(pc_imbalanced)
screeplot(pc_imbalanced)

g_imbalanced <- ggbiplot(pc_imbalanced, obs.scale = 1, var.scale = 1, 
                         groups = training_data$stroke,
                         ellipse = TRUE, circle = TRUE,
                         ellipse.prob = 0.75) + 
  theme(legend.direction = 'horizontal', legend.position = 'top') +
  theme_bw() + 
  ggtitle("Principal Component Analysis for Imbalanced Classes")

g_imbalanced
#Principal Component Analysis -- balanced classes
pc_balanced <- prcomp(data_rose_0.5, center = TRUE, scale. = TRUE)
pc_balanced$scale # checking the scale to see that the sd is calculated for each variable.
print(pc_balanced)
summary(pc_balanced)
screeplot(pc_balanced)

g_balanced <- ggbiplot(pc_balanced, obs.scale = 1, var.scale = 1, 
                       groups = data_rose_0.5$stroke,
                       ellipse = TRUE, circle = TRUE, 
                       ellipse.prob = 0.75) + 
  theme(legend.direction = 'horizontal', legend.position = 'top') +
  theme_bw() + 
  ggtitle("Principal Component Analysis for Balanced Classes")

g_balanced
```

# Modeling

## Partitioning data

```{r partition, include=FALSE, echo=TRUE, fig.cap="A caption", out.width = '100%'}
# set seed
set.seed(13) 
## divide stroke cases into train/test with an index
data_rose_0.5_stroke <- data_rose_0.5 %>% filter(stroke == 1) # all stroke cases
# randomly select 90% of rows
stroke_index <- sample(seq_len(nrow(data_rose_0.5_stroke)), size = 0.9*dim(data_rose_0.5_stroke)[1])
# stroke cases for train data
train_stroke <- data_rose_0.5_stroke[stroke_index, ]
# stroke cases for test data
test_stroke <- data_rose_0.5_stroke[-stroke_index, ]

########################################################################
## divide non-stroke cases into train/test with an index
data_rose_0.5_nostroke <- data_rose_0.5 %>% filter(stroke == 0) # all non-stroke cases
# randomly select 90% of rows
nostroke_index <- sample(seq_len(nrow(data_rose_0.5_nostroke)), size = 0.9*dim(data_rose_0.5_nostroke)[1])
# non-stroke cases for train data
train_nostroke <- data_rose_0.5_nostroke[nostroke_index, ]
# non-stroke cases for test data
test_nostroke <- data_rose_0.5_nostroke[-nostroke_index, ]

########################################################################
## combining respective train/test data frames for stroke/non-stroke
train <- rbind(train_stroke, train_nostroke)
test <- rbind(test_stroke, test_nostroke)
dim(train) # 36146 x 14
dim(test) # 4017 x 14
########################################################################
rm(data_rose_0.5_stroke, stroke_index, train_stroke, test_stroke,
   data_rose_0.5_nostroke, nostroke_index, train_nostroke, test_nostroke)
```

## Logistic Regression

In this subsection, we train a logistic regression model using the `glm` package. 

We calculate the class probabilities together with the class predictions and assess performance via the so-called `confusion matrix`.

```{r logsitic, eval = TRUE, fig.cap="A caption", out.width = '100%'}
## Logistic regression

logit <- stats::glm(formula = formula_linear, data = train, family = "binomial")

test$prob_logit <- predict(logit, newdata = test, type = "response")
test$link_logit <- predict(logit, newdata = test, type = "link")
test <- test %>% mutate(pred_logit = as.factor(ifelse(prob_logit > 0.5, 1, 0)),
                        stroke = as.factor(stroke))

## Visualization of logistic regression (logits versus class probabilities)
ggplot(test, aes(x = link_logit, y = prob_logit, color = pred_logit)) +
  geom_line(lwd=2) +
  labs(x= "Logits", y = "Probability", title="Probability of Stroke") + 
  theme_bw() + 
  scale_color_brewer(palette = "PuRd") +
  xlim(-5, 5)

## Confusion matrix
confusion_matrix_logit <- confusionMatrix(test$pred_logit, test$stroke, positive = "1")
confusion_matrix_logit$table

## ROC curve with AUC
ROSE::roc.curve(response = test$stroke, predicted = test$pred_logit)
```

## Neural network

In this subsection, we train a neural network using the `neuralnet` package. We experimented with a variety of activiation functions, learning algorthims and neural network architectures. Ultimately, we decided to use 1 hidden layer with 2 neurons, binary cross entropy as the error function, sigmoid activation function and resilient backpropagation with backtracking algorithm. 

We calculate the class probabilities together with the class predictions and assess performance via the so-called `confusion matrix`.

```{r nn, eval = TRUE, fig.cap="A caption", out.width = '100%'}
## NN
#####################################################
# Activation functions considered:
#       softplus <- function(x) {log(1+exp(x))}
#       leaky_relu <- function(x){ifelse(x < 0, 0.01*x, x)}
#       relu <- function(x){ifelse(x < 0, 0, x)}
#####################################################

sigmoid <- function(x) {1.0 / (1.0 + exp(-x))}
nn <- neuralnet::neuralnet(formula = formula_linear, data = train, 
                           lifesign = "full", linear.output = FALSE, 
                           threshold = 5, hidden = 2, startweights = NULL, 
                           err.fct = "ce", act.fct = sigmoid,
                           algorithm = "rprop+", stepmax = 1e7)

test$prob_nn <- predict(nn, newdata = test, type = "response")                       
test <- test %>% mutate(pred_nn = as.factor(ifelse(prob_nn > 0.5, 1, 0)))

## Visualization of NN (built-in method)
plot(nn)

## Confusion matrix
confusion_matrix_nn <- confusionMatrix(test$pred_nn, test$stroke, positive = "1")
confusion_matrix_nn$table

## ROC curve with AUC
ROSE::roc.curve(response = test$stroke, predicted = test$pred_nn)
```

## Random forest

In this subsection, we train a random forest model using the `randomForest` package. We experimented with various values for the tree number and noticed diminishing returns for values greater than ~150. We agreed that the other parameters were reasonable for our use case (e.g. `mtry`).  

We calculate the class probabilities together with the class predictions and assess performance via the so-called `confusion matrix`.

```{r rf, eval = TRUE, fig.cap="A caption", out.width = '100%'}
# Random forest

rf <- randomForest::randomForest(formula = formula_linear, data = train, 
                                 ntree = 150, importance = TRUE)

test$prob_rf <- predict(rf, test, type = "response")
test <- test %>% mutate(pred_rf = as.factor(ifelse(prob_rf > 0.5, 1, 0)))

## Optimal tree number
plot(rf)

# Variable importance
imp_matrix <- randomForest::importance(x = rf, type = 2)
imp <- data.frame(imp_matrix)
imp <- imp %>% 
  dplyr::mutate(features = row.names(imp)) %>% 
  dplyr::arrange(desc(IncNodePurity)) %>% 
  dplyr::select(features, IncNodePurity) %>%
  dplyr::rename(importance = IncNodePurity)

rm(imp_matrix)
imp # Variable importance

## Visualization of RF (work around using tree package)
####################################################################
## Using tree package to create visualization of representative tree
X <- tree(stroke ~ gender + hypertension + heart_disease + ever_married + 
            Residence_type + avg_glucose_level + bmi + work_type_children + 
            work_type_Self_employed + work_type_Govt_job, 
          data = train, split = "deviance")
plot(X)
text(X)
####################################################################

## Confusion matrix
confusion_matrix_rf <- confusionMatrix(test$pred_rf, test$stroke, positive = "1")
confusion_matrix_rf$table

## ROC curve with AUC
ROSE::roc.curve(response = test$stroke, predicted = test$pred_rf)
```

## Voting classifier

In this subsection, we consider ensembles of the 3 models above in the form of voting classifiers. We construct a weighted classifiers to compare performance to each model indiviudally.   

```{r vote, eval = TRUE, fig.cap="A caption", out.width = '100%'}
## Voting classifier
test <- test %>% dplyr::mutate(prob_soft_vote = (test$prob_logit + test$prob_nn + test$prob_rf)/3)
test <- test %>% dplyr::mutate(pred_soft_vote = as.factor(ifelse(prob_soft_vote > 0.5, 1, 0)))

## Confusion matrix
confusion_matrix_soft_vote <- confusionMatrix(test$pred_soft_vote, test$stroke, positive = "1")
confusion_matrix_soft_vote$table

## ROC curve with AUC
ROSE::roc.curve(response = test$stroke, predicted = test$pred_soft_vote)
```

## Validation

Note that, thus far, models have been trained and evaluated using a 90%-10% train-test split of the **balanced class data**. Here we further evaluate performance of our models by predicting stroke for the original, i.e. imbalanced, data set (denoted `training_data`).

```{r validation, eval = TRUE,fig.cap="A caption", out.width = '100%'}
# Recall
names(training_data)
dim(training_data)
# Converting stroke to factor, remove id variable
training_data <- training_data %>% dplyr::mutate(stroke = as.factor(stroke)) %>% dplyr::select(-id)

### Predictions on original data
# logistic regression
training_data$prob_logit <- predict(logit, newdata = training_data, type = "response")
training_data <- training_data %>% mutate(pred_logit = as.factor(ifelse(prob_logit > 0.5, 1, 0)))

confusionMatrix(training_data$pred_logit, training_data$stroke, positive = "1")

# neural network
training_data$prob_nn <- predict(nn, newdata = training_data, type = "response")
training_data <- training_data %>% mutate(pred_nn = as.factor(ifelse(prob_nn > 0.5, 1, 0)))

confusionMatrix(training_data$pred_nn, training_data$stroke, positive = "1")

# random forest
training_data$prob_rf <- predict(rf, newdata = training_data, type = "response")
training_data <- training_data %>% mutate(pred_rf = as.factor(ifelse(prob_rf > 0.5, 1, 0)))

confusionMatrix(training_data$pred_rf, training_data$stroke, positive = "1")

## Voting classifier
training_data<- training_data %>% dplyr::mutate(prob_soft_vote = (training_data$prob_logit + training_data$prob_nn + training_data$prob_rf)/3)
training_data<- training_data %>% dplyr::mutate(pred_soft_vote = as.factor(ifelse(prob_soft_vote > 0.5, 1, 0)))

confusionMatrix(training_data$pred_soft_vote, training_data$stroke, positive = "1")
```

## Miscellaneous: 2nd order terms

```{r rf_2o, eval = TRUE, fig.cap="A caption", out.width = '100%'}
# Random forest with second order terms
rf_2o <- randomForest::randomForest(formula = stroke ~ gender + age + hypertension + heart_disease + ever_married + Residence_type + avg_glucose_level + bmi + work_type_children + work_type_Self_employed + I(age^2) + I(bmi^2) + I(avg_glucose_level^2) +  I(age*ever_married) + I(bmi*ever_married) + I(avg_glucose_level*ever_married) +  I(age*heart_disease) + I(bmi*heart_disease) + I(avg_glucose_level*heart_disease) + I(age*hypertension) + I(bmi*hypertension) + I(avg_glucose_level*hypertension) + I(age*gender) + I(bmi*gender) + I(avg_glucose_level*gender) , data = train, ntree = 100, importance = TRUE)

# Variable importance
imp_matrix_2o <- randomForest::importance(x = rf_2o, type = 2)
imp_2o <- data.frame(imp_matrix_2o)
imp_2o <- imp_2o %>% 
  dplyr::mutate(features = row.names(imp_2o)) %>% 
  dplyr::arrange(desc(IncNodePurity)) %>% 
  dplyr::select(features, IncNodePurity) %>%
  dplyr::rename(importance = IncNodePurity)

rm(imp_matrix_2o)
imp_2o # Variable importance with 2nd order terms
```

# Conclusion

## Summary 

Based on the performance both on balanced and imbalanced data, the random forest seems to be the best model. It it simultaneously the most accurate, sensitive and specific model assessed in this project. In fact, the random forest model is so sensitive that it **never** predicts a stroke outcome when the outcome is not a stroke occurrence.

## Reflections

After completing the primary modeling effort, it appears that diving deeper into second order terms may have been a fruitful venture but was not incorporated in the models. In addition, while principal component analysis comveys a clear message about the trends in the data, it may have also been worthwhile to consider linear or quadratic discriminant analysis as well to best understand how and why the stroke and non-stroke classes separate. 
